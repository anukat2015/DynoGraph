{"name":"DynoGraph","tagline":"","body":"# DynoGraph\r\n\r\n> (c) 2014 Georgia Tech Research Institute\r\n> Released under GPL v3.0.  See LICENSE for full details\r\n\r\nDynoGraph is a suite of benchmarks centered\r\naround streaming graph analytics. With the prevalence of\r\nsocial media and the need to process real-time network graphs,\r\nstreaming dynamic graphs have become a very important application.\r\nMany solutions exist for graph-based analysis including\r\ngraph databases, custom representation using\r\nformats such as compressed sparse row (CSR), or in-memory\r\ndata structures such as STINGER. GraphBench derives\r\nfrom STINGER, which employs in-memory storage and has\r\nproven results at processing large graphs in real-time.\r\nGraphBench includes three algorithms run on four real-world\r\ninputs: breadth first search, streaming connected components,\r\nand pagerank centrality. These algorithms\r\nare highly data dependent, have unpredictable access\r\npatterns, and are unique in their microarchitecture behavior compared\r\nto other benchmark suites.\r\n\r\n> A paper detailing the microarchitecture characteristics of GraphBench is currently under review and will eventually be released here.\r\n\r\n## Usage\r\n\r\nTo build the workloads simply do \r\n\r\n```\r\nmake\r\n```\r\n\r\nThis will build four workloads, `bfs`, `components`, `pagerank`, and `edge_stream`.  The workloads each expect a single input which is a graph edge list file.  The data files are provided in the `data/` directory.\r\n\r\n* `coAuthorsDBLP` - Co-authorship network.  Largest graph in suite\r\n* `cond-mat-2003` - Co-authorship network.\r\n* `PGPgiantcompo` - PGP trust network\r\n* `ny_sandy` - Twitter feed collected during Hurricane Sandy\r\n\r\nThere are **two versions** of each data file, one includes edge or vertex deletions and the other does not.  In an edge list a deletion is noted by a `-` sign preceding the edge.  If the second value in a deletion is a `0`, then this represents a vertex deletion.  If the second value is non-zero, then it is a single edge deletion.\r\n\r\nThe first three inputs were collected from the 10th annual DIMACS challenge and repurposed to represent the behavior of dynamic graphs.  Ten percent of the original nodes were duplicated and injected into the permuted edge stream.  At the end of the insertion, these nodes are deleted such that the remaining structure is representative of a streaming graph with insertions and deletions happening simultaneously.\r\n\r\nThe fourth input is a streaming input taken from Twitter.  Batches of edges stream in, and older edges are rolled off periodically.  There are two streaming *phases* to the ny_sandy edge list.  In the first phase insertions and deletions alternate.  In the second phase, a big burst of insertions is injected into the graph.\r\n\r\nThe **no deletions** versions of the inputs are the same graphs without any injected deletions, creating a more packed graph structure.\r\n\r\n> The no deletions version are provided as reference and are representative of static graph analysis, **not** dynamic graph analysis.\r\n\r\nBelow is a summary of the graph structures and statistics.\r\n\r\n| | Vertices | Edges | Edge Blocks | Empty Edge Blocks | Fragmented Edge Blocks | Edge Block Fill % | Avg. Edges per Block | \r\n| --- | --- | --- | --- | --- | --- | --- | --- |\r\n| `PGPgiantcompo` | 10680 | 24316 | 15939 | 3660 | 7426 | 21.8 | 3.96 |\r\n| `cond-mat-2003` | 30460 | 120029 | 51525 | 11890 | 30941 | 33.3 | 6.06 |\r\n| `coAuthorsDBLP` | 299067 | 977676 | 475650 | 109124 | 270332 | 29.4 | 5.33 |\r\n| `ny_sandy` | 44062 | 77348 | 72717 | 27947 | 1628 | 7.6 | 1.72 |\r\n\r\nWe do anticipate releasing scripts that allow generation of more versions of each of these input files with different deletion factors, and eventually there will be scripts provided to convert new data sets as GraphBench inputs.\r\n\r\n### Test Harness\r\n\r\nAn effective benchmark requires a test harness that allows for\r\nseparation of concerns. Setup and initialization should be done\r\nefficiently during untimed portions of the code, and the region\r\nof interest should be clearly delineated. For the algorithms\r\nonly the graph algorithm is timed and measured. Except for the `edge_stream` workload, loading of\r\nthe data into the graph from the input files is untimed and\r\nshould not be considered for design decisions. This ingest is\r\ndone artificially and is not representative of the patterns that\r\noccur during typical streaming graph ingest.\r\n\r\nThe `edge_stream` workload should use the `ny_sandy` input with deletions only.  More data inputs will be provided in future updates.\r\n\r\nTo help delineate the test harness, `bench_start()` and `bench_end()` functions calls have been placed in the appropriate locations.  The body of these functions can be found in `src/lib/hooks.c`.\r\n\r\n## Algorithms\r\n\r\n### BFS\r\n\r\nThe breadth first search calculates\r\nthe distance of every vertex in the graph from a given\r\nsource vertex. Two auxiliary data structures are used: a distance score and a flag indicating that a vertex has been processed,\r\nboth per-vertex. Two global queues are employed\r\nto track vertices currently being processed (the current frontier)\r\nand vertices about to be processed (the next frontier). At\r\neach level of the breadth first search, starting from the source,\r\nneighbors of vertices in the current frontier that have not been\r\nvisited are enqueued in the next frontier and their distance is\r\nset accordingly. This process repeats until all vertices have\r\nbeen visited or there are no more vertices in the queue.\r\n\r\nThe breadth first search algorithm has a vertex-centric access\r\npattern. The edge blocks of the adjacency list of a vertex\r\nare read in succession. Each vertex is processed only once and\r\neach edge block is accessed only once.\r\n\r\n### Connected Components\r\n\r\nConnected components establishes\r\na label for each vertex such that vertices with the\r\nsame label are in the same component. Vertices in a component\r\nare connected, whereas vertices in different components\r\nare not connected. The Shiloach-Vishkin algorithm for\r\nconnected components begins by labeling each vertex in its\r\nown component. In each iteration, all vertices adopt the smallest\r\nlabel of their neighbors. When the computation converges,\r\neach vertex will be labeled with the identifier of the smallest\r\nvertex in the connected component.\r\n\r\nThe connected components algorithm is edge-centric. Every\r\nedge block is accessed during each iteration until convergence.\r\nEdge blocks are accessed via a global edge block list for\r\nmaximum parallelism and efficient work distribution.\r\n\r\n### PageRank Centrality\r\n\r\nPageRank centrality calculates the likelihood of arriving at a vertex via random walks about\r\nthe graph. It includes a factor that accounts for random jumping\r\nin the network. Each vertex maintains its current centrality\r\nscore and distributes that score evenly to all of its neighbors\r\nin each iteration until the algorithm converges. Convergence\r\nis usually reached around 100 iterations.\r\n\r\nThe PageRank centrality algorithm employs a power iteration,\r\nvertex-centric access pattern that employs a gather\r\noperation to avoid write-locking. Scores are double precision\r\nfloating point and allocated per-vertex. The edge blocks of the\r\nadjacency list of a vertex are read in succession during each\r\niteration.\r\n\r\n## Characterization\r\n\r\n> Upon release of the accompanying paper on the GraphBench characteristics.  The paper summary will be provided here.\r\n\r\n\r\n","google":"UA-55019195-1","note":"Don't delete this file! It's used internally to help with page regeneration."}